{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "204be431-2f23-4459-a7a8-3913ddc6375e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Semantic Segmentation of House Tour Videos\n",
    "The first half of this notebook was adapted from the following [notebook](https://github.com/CSAILVision/semantic-segmentation-pytorch/tree/master/notebooks) which was originally made for running the benchmark semantic segmentation network from the the [ADE20K MIT Scene Parsing Benchchmark](http://sceneparsing.csail.mit.edu/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f6e1dd-1717-424a-91f2-f2a8f0e7b01a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "Before running this notebook, make sure you have extracted all video frames (with numbers in the file name) and make sure you have the following folder structure:\n",
    "```\n",
    "├── Backprojection_CSAIL.ipynb\n",
    "├── config\n",
    "    ├── color150.mat\n",
    "    ├── object150_info.csv\n",
    "    ├── encoder_epoch_20.pth\n",
    "    ├── decoder_epoch_20.pth\n",
    "    └── ...\n",
    "├── mit_semseg\n",
    "    └── ...\n",
    "└── PROJECT\n",
    "    ├── img                              //Image frames (numbered from 1...n)\n",
    "        └── ...\n",
    "    ├── Model                            //Output folder from COLMAP\n",
    "        ├── cameras.txt \n",
    "        ├── images.txt\n",
    "        ├── points3D.txt\n",
    "        └── project.ini\n",
    "    ├── Model_Original                   //Backup copy of COLMAP output\n",
    "        ├── cameras.txt\n",
    "        ├── images.txt\n",
    "        ├── points3D.txt\n",
    "        └── project.ini\n",
    "    ├── DB.db                            //Database needed in COLMAP\n",
    "    ├── labels.txt                       //Labels mentioned in subtitles\n",
    "    └── PROJECT_segmentation.npy         //Segmentation output from 1st part\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2170f5b-3ed0-4675-8c87-bef1ebcc8a9d",
   "metadata": {},
   "source": [
    "## GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4ef15-54c6-488e-b353-5f79dede4ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 1920\n",
    "HEIGHT = 1080\n",
    "START_FRAME = 0\n",
    "END_FRAME = 9018\n",
    "#This should just be the name of the folder containing all the things shown above\n",
    "PROJECT = \"_FINAL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3c496-926e-4672-b7e6-b2b2a11dee48",
   "metadata": {},
   "source": [
    "## Imports and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c30d7ce-2720-4be0-8c94-fff7d26bd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parts taken from here: https://github.com/CSAILVision/semantic-segmentation-pytorch/blob/master/notebooks/DemoSegmenter.ipynb\n",
    "\n",
    "# System libs\n",
    "import os, csv, torch, numpy, scipy.io, PIL.Image, torchvision.transforms \n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "# Our libs\n",
    "from mit_semseg.models import ModelBuilder, SegmentationModule\n",
    "from mit_semseg.utils import colorEncode\n",
    "\n",
    "colors = scipy.io.loadmat('config/color150.mat')['colors']\n",
    "names = {}\n",
    "with open('config/object150_info.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        names[int(row[0])] = row[5].split(\";\")[0]\n",
    "\n",
    "def visualize_result(img, pred, index=None):\n",
    "    # filter prediction class if requested\n",
    "    if index is not None:\n",
    "        pred = pred.copy()\n",
    "        pred[pred != index] = -1\n",
    "        print(f'{names[index+1]}:')\n",
    "        \n",
    "    # colorize prediction\n",
    "    pred_color = colorEncode(pred, colors).astype(numpy.uint8)\n",
    "\n",
    "    # aggregate images and save\n",
    "    im_vis = numpy.concatenate((img, pred_color), axis=1)\n",
    "    display(PIL.Image.fromarray(im_vis))\n",
    "    \n",
    "# Network Builders\n",
    "net_encoder = ModelBuilder.build_encoder(\n",
    "    arch='resnet50dilated',\n",
    "    fc_dim=2048,\n",
    "    #ADJUST PATH HERE:\n",
    "    weights='config/encoder_epoch_20.pth')\n",
    "net_decoder = ModelBuilder.build_decoder(\n",
    "    arch='ppm_deepsup',\n",
    "    fc_dim=2048,\n",
    "    num_class=150,\n",
    "    #ADJUST PATH HERE:\n",
    "    weights='config/decoder_epoch_20.pth',\n",
    "    use_softmax=True)\n",
    "\n",
    "crit = torch.nn.NLLLoss(ignore_index=-1)\n",
    "segmentation_module = SegmentationModule(net_encoder, net_decoder, crit)\n",
    "segmentation_module.eval()\n",
    "segmentation_module.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a11090-1501-4ade-a910-bf6c294634c2",
   "metadata": {},
   "source": [
    "## Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d950bd-70a8-40c4-8ce9-e1b12f1080d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this only if you want to create a new segmentation numpy file\n",
    "# WARNING: You need around 18GB of RAM if the video has around 9000 frames \n",
    "\n",
    "# Empty array that stores the labels of all pixels of all frames\n",
    "predictions = np.empty((END_FRAME - START_FRAME, HEIGHT, WIDTH),dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(START_FRAME, END_FRAME)):\n",
    "    # ADJUST IMAGE PATH HERE:\n",
    "    image_name = PROJECT + \"/img/frame_id_\" + f'{i+1:04d}' + \".jpg\"\n",
    "\n",
    "\n",
    "    # Load and normalize one image as a singleton tensor batch\n",
    "    pil_to_tensor = torchvision.transforms.Compose([\n",
    "      torchvision.transforms.ToTensor(),\n",
    "      torchvision.transforms.Normalize(\n",
    "          mean=[0.485, 0.456, 0.406], # These are RGB mean+std values\n",
    "          std=[0.229, 0.224, 0.225])  # across a large photo dataset.\n",
    "    ])\n",
    "    pil_image = PIL.Image.open(image_name).convert('RGB')\n",
    "    img_original = numpy.array(pil_image)\n",
    "    img_data = pil_to_tensor(pil_image)\n",
    "    singleton_batch = {'img_data': img_data[None].cuda()}\n",
    "    output_size = img_data.shape[1:]\n",
    "\n",
    "\n",
    "    # Run the segmentation at the highest resolution.\n",
    "    with torch.no_grad():\n",
    "      scores = segmentation_module(singleton_batch, segSize=output_size)\n",
    "\n",
    "    # Get the predicted scores for each pixel\n",
    "    _, pred = torch.max(scores, dim=1)\n",
    "    pred = pred.cpu()[0].numpy()\n",
    "    \n",
    "    predictions[i] = pred.astype(dtype=np.uint8)\n",
    "        \n",
    "\n",
    "print(predictions.shape)\n",
    "\n",
    "np.save(PROJECT +'/' + PROJECT +'_segmentation', predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c078e-8fdf-4c38-afb4-cd6b4803555f",
   "metadata": {},
   "source": [
    "## Colouring 3D Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1b484-81e0-4a68-891d-0160f489e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLMAP helper functions, taken from here: https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
    "\n",
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import struct\n",
    "import argparse\n",
    "\n",
    "BaseImage = collections.namedtuple(\n",
    "    \"Image\", [\"id\", \"qvec\", \"tvec\", \"camera_id\", \"name\", \"xys\", \"point3D_ids\"])\n",
    "Point3D = collections.namedtuple(\n",
    "    \"Point3D\", [\"id\", \"xyz\", \"rgb\", \"error\", \"image_ids\", \"point2D_idxs\"])\n",
    "\n",
    "class Image(BaseImage):\n",
    "    def qvec2rotmat(self):\n",
    "        return qvec2rotmat(self.qvec)\n",
    "\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])    \n",
    "\n",
    "    \n",
    "def read_points3D_text(path):\n",
    "    points3D = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                point3D_id = int(elems[0])\n",
    "                xyz = np.array(tuple(map(float, elems[1:4])))\n",
    "                rgb = np.array(tuple(map(int, elems[4:7])))\n",
    "                error = float(elems[7])\n",
    "                image_ids = np.array(tuple(map(int, elems[8::2])))\n",
    "                point2D_idxs = np.array(tuple(map(int, elems[9::2])))\n",
    "                points3D[point3D_id] = Point3D(id=point3D_id, xyz=xyz, rgb=rgb,\n",
    "                                               error=error, image_ids=image_ids,\n",
    "                                               point2D_idxs=point2D_idxs)\n",
    "    return points3D\n",
    "\n",
    "def read_images_text(path):\n",
    "    images = {}\n",
    "    with open(path, \"r\") as fid:\n",
    "        while True:\n",
    "            line = fid.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != \"#\":\n",
    "                elems = line.split()\n",
    "                image_id = int(elems[0])\n",
    "                qvec = np.array(tuple(map(float, elems[1:5])))\n",
    "                tvec = np.array(tuple(map(float, elems[5:8])))\n",
    "                camera_id = int(elems[8])\n",
    "                image_name = elems[9]\n",
    "                elems = fid.readline().split()\n",
    "                xys = np.column_stack([tuple(map(float, elems[0::3])),\n",
    "                                       tuple(map(float, elems[1::3]))])\n",
    "                point3D_ids = np.array(tuple(map(int, elems[2::3])))\n",
    "                images[image_id] = Image(\n",
    "                    id=image_id, qvec=qvec, tvec=tvec,\n",
    "                    camera_id=camera_id, name=image_name,\n",
    "                    xys=xys, point3D_ids=point3D_ids)\n",
    "    return images\n",
    "\n",
    "def write_points3D_text(points3D, path):\n",
    "    if len(points3D) == 0:\n",
    "        mean_track_length = 0\n",
    "    else:\n",
    "        mean_track_length = sum((len(pt.image_ids) for _, pt in points3D.items()))/len(points3D)\n",
    "    HEADER = \"# 3D point list with one line of data per point:\\n\" + \\\n",
    "             \"#   POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK[] as (IMAGE_ID, POINT2D_IDX)\\n\" + \\\n",
    "             \"# Number of points: {}, mean track length: {}\\n\".format(len(points3D), mean_track_length)\n",
    "\n",
    "    with open(path, \"w\") as fid:\n",
    "        fid.write(HEADER)\n",
    "        for _, pt in tqdm(points3D.items()):\n",
    "            point_header = [pt.id, *pt.xyz, *pt.rgb, pt.error]\n",
    "            fid.write(\" \".join(map(str, point_header)) + \" \")\n",
    "            track_strings = []\n",
    "            for image_id, point2D in zip(pt.image_ids, pt.point2D_idxs):\n",
    "                track_strings.append(\" \".join(map(str, [image_id, point2D])))\n",
    "            fid.write(\" \".join(track_strings) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e337d0-5cc7-460b-b2a6-634bfe784259",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d2387-b145-4e3c-bcd3-3baad81baec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = read_points3D_text(PROJECT + \"/Model/points3D.txt\")\n",
    "# To keep original pts clean up until just before overwriting\n",
    "res_pts = pts.copy()\n",
    "ims = read_images_text(PROJECT + \"/Model/images.txt\")\n",
    "\n",
    "# Load and preview keywords\n",
    "keywords = np.loadtxt(PROJECT + \"/labels.txt\", dtype=str)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e913f-176c-45d0-a34e-d5a35014dd19",
   "metadata": {},
   "source": [
    "### Create all possible mapping from 3D points to other information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc90f4-ca99-4b9e-91d8-c67b44a8118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all necessary of dictionaries; \"3D\" means the ID of a 3D pt\n",
    "\n",
    "# Create first dictionary going from point-ID to all contributing imageIDs and their pixel coordinates\n",
    "dict_3D_to_imageIDs = {}\n",
    "for k in tqdm(pts.keys()):\n",
    "    dict_3D_to_imageIDs[k] = np.column_stack((pts[k].image_ids,pts[k].point2D_idxs))\n",
    "                                             #Left: imageId, right: index of x,y\n",
    "\n",
    "print(len(pts.keys()))\n",
    "\n",
    "# Create second dictionary going from point-ID to filename, imageID and pixel coordinates\n",
    "dict_3D_to_imageName_XY = {}\n",
    "for k in tqdm(dict_3D_to_imageIDs.keys()):\n",
    "    #Make list for all corresponding images\n",
    "    dict_3D_to_imageName_XY[k] = []\n",
    "    for tup in dict_3D_to_imageIDs[k]:\n",
    "        #For all images mentioend in 3D point, get tuple of name, imageID and X,Y\n",
    "        dict_3D_to_imageName_XY[k].append((ims[tup[0]].name, tup[1], list(np.rint(ims[tup[0]].xys[tup[1]]).astype(int))))\n",
    "      \n",
    "    \n",
    "    \n",
    "segmentation_labels = np.load(PROJECT +\"/\" + PROJECT +\"_segmentation.npy\")\n",
    "print(segmentation_labels.shape)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "dict_3D_to_labels = {}\n",
    "\n",
    "for k in tqdm(dict_3D_to_imageName_XY):\n",
    "    label_list = []\n",
    "    for trip in dict_3D_to_imageName_XY[k]:\n",
    "        #Extract frame number from image name (e.g., \"out23.png\" -> 23)\n",
    "        frame_number = int(re.search(r'\\d+', trip[0]).group())\n",
    "        # Get pixel coordinates\n",
    "        x = trip[2][0]-1\n",
    "        y = trip[2][1]-1\n",
    "        # Get pixel label\n",
    "        lbl = segmentation_labels[int(frame_number)-1][y][x]\n",
    "        \n",
    "        #Supression: only count votes for classes that were used for segmentation\n",
    "        if(names[lbl+1] in keywords):\n",
    "            label_list.append(lbl)\n",
    "    dict_3D_to_labels[k] = label_list  \n",
    "    \n",
    "# Helper function used to get most common class label for each point\n",
    "from collections import Counter\n",
    "def Most_Common(lst):\n",
    "    if (lst):        \n",
    "        data = Counter(lst)\n",
    "        return int(data.most_common(1)[0][0])\n",
    "\n",
    "\n",
    "# For each pointID get most common label\n",
    "dict_3D_to_SINGLE_LABEL = {}\n",
    "for k in tqdm(dict_3D_to_labels.keys()):\n",
    "    # Use voting strategy on each label list\n",
    "    dict_3D_to_SINGLE_LABEL[k] = Most_Common(dict_3D_to_labels[k])\n",
    "    \n",
    "print(len(dict_3D_to_SINGLE_LABEL.keys()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1f215-0751-4679-8640-3bf4f0b5d75b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Colour dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bb0cd-4eb3-4b18-b055-9f129f0dd816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colours used for final segmentation colours\n",
    "\n",
    "colours = {\n",
    "    0 : [120 , 120 , 120],\n",
    "    1 : [180 , 120 , 120],\n",
    "    2 : [6 , 230 , 230],\n",
    "    3 : [80 , 50 , 50],\n",
    "    4 : [4 , 200 , 3],\n",
    "    5 : [120 , 120 , 80],\n",
    "    6 : [140 , 140 , 140],\n",
    "    7 : [173, 0, 255],\n",
    "    8 : [129, 238, 185],\n",
    "    9 : [176, 254, 98],\n",
    "    10 : [255, 0, 255],\n",
    "    11 : [235 , 255 , 7],\n",
    "    12 : [150 , 5 , 61],\n",
    "    13 : [120 , 120 , 70],\n",
    "    14 : [8, 255, 51],\n",
    "    15 : [255, 0, 0],\n",
    "    16 : [143 , 255 , 140],\n",
    "    17 : [176, 254, 98],\n",
    "    18 : [0, 255, 255],\n",
    "    19 : [0, 0, 255],\n",
    "    20 : [0 , 102 , 200],\n",
    "    21 : [61 , 230 , 250],\n",
    "    22 : [255, 176, 0],\n",
    "    23 : [173, 0, 255],\n",
    "    24 : [252, 93, 0],\n",
    "    25 : [255, 9, 224],\n",
    "    26 : [9 , 7 , 230],\n",
    "    27 : [220, 220, 220],\n",
    "    28 : [138, 64, 191],\n",
    "    29 : [112 , 9 , 255],\n",
    "    30 : [0, 0, 255],\n",
    "    31 : [0, 0, 255],\n",
    "    32 : [255 , 184 , 6],\n",
    "    33 : [255, 0, 0],\n",
    "    34 : [255 , 41 , 10],\n",
    "    35 : [255, 0, 255],\n",
    "    36 : [0 , 255, 0],\n",
    "    37 : [102 , 8 , 255],\n",
    "    38 : [255 , 61 , 6],\n",
    "    39 : [0, 255 , 198],\n",
    "    40 : [255 , 122 , 8],\n",
    "    41 : [206, 92, 0],\n",
    "    42 : [255 , 8 , 41],\n",
    "    43 : [255 , 5 , 153],\n",
    "    44 : [252, 93, 0],\n",
    "    45 : [235 , 12 , 255],\n",
    "    46 : [160 , 150 , 20],\n",
    "    47 : [150, 79, 165],\n",
    "    48 : [140 , 140 , 140],\n",
    "    49 : [250 , 10 , 15],\n",
    "    50 : [20, 255, 0],\n",
    "    51 : [31 , 255 , 0],\n",
    "    52 : [255 , 31 , 0],\n",
    "    53 : [255 , 224 , 0],\n",
    "    54 : [153 , 255 , 0],\n",
    "    55 : [0 , 0 , 255],\n",
    "    56 : [255 , 0, 0],\n",
    "    57 : [0, 255 , 198],\n",
    "    58 : [0 , 173 , 255],\n",
    "    59 : [31, 0, 255],\n",
    "    60 : [11 , 200 , 200],\n",
    "    61 : [255 , 82 , 0],\n",
    "    62 : [0 , 255 , 245],\n",
    "    63 : [0 , 61 , 255],\n",
    "    64 : [255 , 0, 0],\n",
    "    65 : [0 , 255 , 133],\n",
    "    66 : [255 , 0 , 10],\n",
    "    67 : [255 , 163 , 0],\n",
    "    68 : [176, 254, 98],\n",
    "    69 : [255 , 0, 0],\n",
    "    70 : [255 , 0, 0],\n",
    "    71 : [51 , 255 , 0],\n",
    "    72 : [0 , 82 , 255],\n",
    "    73 : [0 , 255 , 41],\n",
    "    74 : [143, 89, 2],\n",
    "    75 : [0, 0, 255],\n",
    "    76 : [173 , 255 , 0],\n",
    "    77 : [0 , 255 , 153],\n",
    "    78 : [255 , 92 , 0],\n",
    "    79 : [255 , 0 , 255],\n",
    "    80 : [255 , 0 , 245],\n",
    "    81 : [0, 255, 255],\n",
    "    82 : [0 , 255, 0],\n",
    "    83 : [255 , 0 , 20],\n",
    "    84 : [255 , 184 , 184],\n",
    "    85 : [0 , 255, 0],\n",
    "    86 : [0 , 255 , 61],\n",
    "    87 : [0 , 255, 0],\n",
    "    88 : [255 , 0 , 204],\n",
    "    89 : [255, 255, 0],\n",
    "    90 : [0 , 255 , 82],\n",
    "    91 : [0 , 10 , 255],\n",
    "    92 : [0, 255, 255],\n",
    "    93 : [51 , 0 , 255],\n",
    "    94 : [0 , 194 , 255],\n",
    "    95 : [0 , 122 , 255],\n",
    "    96 : [0 , 255 , 163],\n",
    "    97 : [255 , 153 , 0],\n",
    "    98 : [0 , 255 , 10],\n",
    "    99 : [255 , 112 , 0],\n",
    "    100 : [255, 176, 0],\n",
    "    101 : [82 , 0 , 255],\n",
    "    102 : [163 , 255 , 0],\n",
    "    103 : [255 , 235 , 0],\n",
    "    104 : [8 , 184 , 170],\n",
    "    105 : [133 , 0 , 255],\n",
    "    106 : [0 , 255 , 92],\n",
    "    107 : [184 , 0 , 255],\n",
    "    108 : [245, 121, 0],\n",
    "    109 : [0 , 184 , 255],\n",
    "    110 : [0, 0, 255],\n",
    "    111 : [255 , 0 , 112],\n",
    "    112 : [92 , 255 , 0],\n",
    "    113 : [0 , 224 , 255],\n",
    "    114 : [112 , 224 , 255],\n",
    "    115 : [149, 187, 24],\n",
    "    116 : [163 , 0 , 255],\n",
    "    117 : [153 , 0 , 255],\n",
    "    118 : [71 , 255 , 0],\n",
    "    119 : [255 , 0 , 163],\n",
    "    120 : [255 , 204 , 0],\n",
    "    121 : [255 , 0 , 143],\n",
    "    122 : [0 , 255 , 235],\n",
    "    123 : [133 , 255 , 0],\n",
    "    124 : [94, 183, 102],\n",
    "    125 : [245 , 0 , 255],\n",
    "    126 : [255 , 0 , 122],\n",
    "    127 : [255 , 245 , 0],\n",
    "    128 : [10 , 190 , 212],\n",
    "    129 : [79, 130, 203],\n",
    "    130 : [255, 255, 0],\n",
    "    131 : [0, 255, 255],\n",
    "    132 : [255 , 255 , 0],\n",
    "    133 : [0 , 153 , 255],\n",
    "    134 : [0 , 41 , 255],\n",
    "    135 : [0 , 255 , 204],\n",
    "    136 : [0 , 255, 0],\n",
    "    137 : [41 , 255 , 0],\n",
    "    138 : [173 , 0 , 255],\n",
    "    139 : [0 , 245 , 255],\n",
    "    140 : [71 , 0 , 255],\n",
    "    141 : [255, 255, 0],\n",
    "    142 : [0, 255, 184],\n",
    "    143 : [255, 255, 0],\n",
    "    144 : [184 , 255 , 0],\n",
    "    145 : [0, 133, 255],\n",
    "    146 : [255 , 214 , 0],\n",
    "    147 : [25 , 194 , 194],\n",
    "    148 : [239, 174, 31],\n",
    "    149 : [92 , 0 , 255]\n",
    "}\n",
    "\n",
    "# Class names\n",
    "names = {\n",
    "    0: \"wall\", \n",
    "    1: \"building\", \n",
    "    2: \"sky\", \n",
    "    3: \"floor\", \n",
    "    4: \"tree\", \n",
    "    5: \"ceiling\", \n",
    "    6: \"road\", \n",
    "    7: \"bed\", \n",
    "    8: \"windowpane\", \n",
    "    9: \"grass\", \n",
    "    10: \"cabinet\", \n",
    "    11: \"sidewalk\", \n",
    "    12: \"person\", \n",
    "    13: \"earth\", \n",
    "    14: \"door\", \n",
    "    15: \"table\", \n",
    "    16: \"mountain\", \n",
    "    17: \"plant\", \n",
    "    18: \"curtain\", \n",
    "    19: \"chair\", \n",
    "    20: \"car\", \n",
    "    21: \"water\", \n",
    "    22: \"painting\", \n",
    "    23: \"sofa\", \n",
    "    24: \"shelf\", \n",
    "    25: \"house\", \n",
    "    26: \"sea\", \n",
    "    27: \"mirror\", \n",
    "    28: \"rug\", \n",
    "    29: \"field\", \n",
    "    30: \"armchair\", \n",
    "    31: \"seat\", \n",
    "    32: \"fence\", \n",
    "    33: \"desk\", \n",
    "    34: \"rock\", \n",
    "    35: \"wardrobe\", \n",
    "    36: \"lamp\", \n",
    "    37: \"bathtub\", \n",
    "    38: \"railing\", \n",
    "    39: \"cushion\", \n",
    "    40: \"base\", \n",
    "    41: \"box\", \n",
    "    42: \"column\", \n",
    "    43: \"signboard\", \n",
    "    44: \"chest\", \n",
    "    45: \"counter\", \n",
    "    46: \"sand\", \n",
    "    47: \"sink\", \n",
    "    48: \"skyscraper\", \n",
    "    49: \"fireplace\", \n",
    "    50: \"refrigerator\", \n",
    "    51: \"grandstand\", \n",
    "    52: \"path\", \n",
    "    53: \"stairs\", \n",
    "    54: \"runway\", \n",
    "    55: \"case\", \n",
    "    56: \"pool\", \n",
    "    57: \"pillow\", \n",
    "    58: \"screen\", \n",
    "    59: \"stairway\", \n",
    "    60: \"river\", \n",
    "    61: \"bridge\", \n",
    "    62: \"bookcase\", \n",
    "    63: \"blind\", \n",
    "    64: \"coffee\", \n",
    "    65: \"toilet\", \n",
    "    66: \"flower\", \n",
    "    67: \"book\", \n",
    "    68: \"hill\", \n",
    "    69: \"bench\", \n",
    "    70: \"countertop\", \n",
    "    71: \"stove\", \n",
    "    72: \"palm\", \n",
    "    73: \"kitchen\", \n",
    "    74: \"computer\", \n",
    "    75: \"swivel\", \n",
    "    76: \"boat\", \n",
    "    77: \"bar\", \n",
    "    78: \"arcade\", \n",
    "    79: \"hovel\", \n",
    "    80: \"bus\", \n",
    "    81: \"towel\", \n",
    "    82: \"light\", \n",
    "    83: \"truck\", \n",
    "    84: \"tower\", \n",
    "    85: \"chandelier\", \n",
    "    86: \"awning\", \n",
    "    87: \"streetlight\", \n",
    "    88: \"booth\", \n",
    "    89: \"television\", \n",
    "    90: \"airplane\", \n",
    "    91: \"dirt\", \n",
    "    92: \"apparel\", \n",
    "    93: \"pole\", \n",
    "    94: \"land\", \n",
    "    95: \"bannister\", \n",
    "    96: \"escalator\", \n",
    "    97: \"ottoman\", \n",
    "    98: \"bottle\", \n",
    "    99: \"buffet\", \n",
    "    100: \"poster\", \n",
    "    101: \"stage\", \n",
    "    102: \"van\", \n",
    "    103: \"ship\", \n",
    "    104: \"fountain\", \n",
    "    105: \"conveyer\", \n",
    "    106: \"canopy\", \n",
    "    107: \"washer\", \n",
    "    108: \"plaything\", \n",
    "    109: \"swimming\", \n",
    "    110: \"stool\", \n",
    "    111: \"barrel\", \n",
    "    112: \"basket\", \n",
    "    113: \"waterfall\", \n",
    "    114: \"tent\", \n",
    "    115: \"bag\", \n",
    "    116: \"minibike\", \n",
    "    117: \"cradle\", \n",
    "    118: \"oven\", \n",
    "    119: \"ball\", \n",
    "    120: \"food\", \n",
    "    121: \"step\", \n",
    "    122: \"tank\", \n",
    "    123: \"trade\", \n",
    "    124: \"microwave\", \n",
    "    125: \"pot\", \n",
    "    126: \"animal\", \n",
    "    127: \"bicycle\", \n",
    "    128: \"lake\", \n",
    "    129: \"dishwasher\", \n",
    "    130: \"screen\", \n",
    "    131: \"blanket\", \n",
    "    132: \"sculpture\", \n",
    "    133: \"hood\", \n",
    "    134: \"sconce\", \n",
    "    135: \"vase\", \n",
    "    136: \"traffic\", \n",
    "    137: \"tray\", \n",
    "    138: \"ashcan\", \n",
    "    139: \"fan\", \n",
    "    140: \"pier\", \n",
    "    141: \"crt\", \n",
    "    142: \"plate\", \n",
    "    143: \"monitor\", \n",
    "    144: \"bulletin\", \n",
    "    145: \"shower\", \n",
    "    146: \"radiator\", \n",
    "    147: \"glass\", \n",
    "    148: \"clock\", \n",
    "    149: \"flag\"\n",
    "}\n",
    "\n",
    "# Dictionary to get colour of each class given a name\n",
    "name_to_colour = {}\n",
    "for k in names.keys():\n",
    "    name_to_colour[names[k]] = colours[k]\n",
    "\n",
    "# Dictionary to get name of class given a concatenated RGB colour string\n",
    "concat_color_to_name = {}\n",
    "for k,v in name_to_colour.items():\n",
    "    rgb_string = str(v[0]) + str(v[1]) + str(v[2])\n",
    "    concat_color_to_name[rgb_string] = k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103465d7-6783-4cc8-bdb5-0d459a4750ab",
   "metadata": {},
   "source": [
    "## Creating mapping from 3D ID to final segmentation colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f710f-c3c0-4084-a1cb-4c85a1757c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prepares the colours of all segmented points\n",
    "\n",
    "# For each pointID get colour of corresponding class that got voted\n",
    "dict_3D_to_RGB = {}\n",
    "for k in tqdm(dict_3D_to_SINGLE_LABEL.keys()):\n",
    "    #Only change colour if label list has voted for at least one label (otherwise errors occur)\n",
    "    if (dict_3D_to_SINGLE_LABEL[k]):\n",
    "        dict_3D_to_RGB[k] = colours[dict_3D_to_SINGLE_LABEL[k]]\n",
    "\n",
    "print(len(dict_3D_to_SINGLE_LABEL.keys()))    \n",
    "\n",
    "        \n",
    "keys = dict_3D_to_RGB.keys()\n",
    "\n",
    "# Make all points black (that way any non-segmented points are black)\n",
    "for k in tqdm(res_pts.keys()):\n",
    "    res_pts[k] = res_pts[k]._replace(rgb=[0, 0, 0])\n",
    "\n",
    "# Now, go over all segmented points and colour the point according to the class RGB value\n",
    "for k in tqdm(keys):\n",
    "    if(dict_3D_to_SINGLE_LABEL[k]):\n",
    "        res_pts[k] = res_pts[k]._replace(rgb=dict_3D_to_RGB[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641b99ed-a0be-4e30-b502-71da327a804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the points to the original .txt file and show the percentage of segmented points\n",
    "write_points3D_text(res_pts, PROJECT +\"/Model/points3D.txt\")\n",
    "print(str(len(dict_3D_to_RGB)) + \" segmented points out of \" + str(len(pts)) + \" total points = \" +  str(100 * len(dict_3D_to_RGB) / len(pts)) + \"%% segmented\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
